{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\[\n",
      "984 \\times \\log_{10}(2) \\approx 293.84\n",
      "\\]\n",
      "\n",
      "(Note: The value uses base-10 logarithm, which is typically assumed unless otherwise specified.)\n",
      "Time taken: 0.727s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PROMPT TEMPLATE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# (1) Chage the Simulated inbounding message\n",
    "# Note: this is the message coming from the interface.\n",
    "MESSAGE = \"984 * log(2)\"\n",
    "\n",
    "# (2) Adjust the Prompt Engineering Technique to be applied\n",
    "TEMPLATE_BEFORE=\"Act like you are a math teacher. Answer to this question from an student:\"\n",
    "TEMPLATE_AFTER=\"Provide the answer only. No explanations!\"\n",
    "PROMPT = TEMPLATE_BEFORE + '\\n' + MESSAGE + '\\n' + TEMPLATE_AFTER\n",
    "\n",
    "# (3) Configure your payload (optional)\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"open-webui\",\n",
    "                         model=\"phi4:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
